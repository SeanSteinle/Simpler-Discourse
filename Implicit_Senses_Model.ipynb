{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implicit_Senses_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-XPPs24lwAm"
      },
      "source": [
        "# Simple Discourse: A Python Library for Clearer Discourse Modeling\n",
        "*A CS1699 Final Project By Sean Steinle, Brandon Kowalecki, and Nolan Weinlader*\n",
        "<br>\n",
        "\n",
        "### Table of Contents\n",
        "1. [The Simple Discourse Library](#a)\n",
        "  1. [Source Code](#a1)\n",
        "  2. [Examining the Discourse Unit and Surveying PDTB3](#a2)\n",
        "\n",
        "<a name='a'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_vtgF_-ma_I"
      },
      "source": [
        "## The Simple Discourse Library\n",
        "\n",
        "In this notebook, we'll demo the Python library we wrote to simplify working with the Penn Discourse TreeBank version 3 (PDTB3).\n",
        "\n",
        "<a name='a1'>\n",
        "\n",
        "### Source Code\n",
        "\n",
        "During the semester, we focused our time on understanding the task of discourse analysis as well as engineering the library itself, so the library is not up on PyPI yet. Because of this, I'll copy our functions into the following blocks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k53TSRtIndqZ"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ8HM8m1nXOX"
      },
      "source": [
        "class DiscourseLoader:\n",
        "    def __init__(self, path):\n",
        "        self.raw_relations = self.loadCorpus(path) #each raw_relation is a two-part tuple, [0] is raw annotation, [1] is raw text\n",
        "\n",
        "    #This method takes the path to the pdtb3 corpus and returns a tuple of the raw text of the discourse fields and the filename\n",
        "    def loadCorpus(self, path):\n",
        "        #This section loads the raw annotations\n",
        "        relations = []\n",
        "        ann_path = path+'gold/'\n",
        "        for folder in os.listdir(ann_path):\n",
        "            if(folder == '.DS_Store'):\n",
        "                continue\n",
        "            for fn in os.listdir(ann_path+folder):\n",
        "                f = open(ann_path+'/'+folder+'/'+fn, 'r')\n",
        "                for line in f.readlines():\n",
        "                    relations.append([line,path+'raw/'+folder+'/'+fn])\n",
        "\n",
        "        return relations\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaeOYOUCjaKN"
      },
      "source": [
        "class DiscourseUnit:\n",
        "    def __init__(self, raw_relation):\n",
        "        fields = raw_relation[0].split('|')\n",
        "\n",
        "        #data members\n",
        "        self.type_definitions_path = 'rel_type_definitions.txt'\n",
        "        self.text_path = raw_relation[1]\n",
        "        self.Relation = Relation(fields[0], fields[7], fields[8]) #connective=7, class=8\n",
        "        self.Arg1 = Arg(fields[14], self.text_path)\n",
        "        self.Arg2 = Arg(fields[20], self.text_path)\n",
        "\n",
        "    def highlightDiscourse(self, text_file, output_file, color1='orange', color2='red', color_con='green', context_len=250): #output needs to be html\n",
        "        htmlFile = '''\n",
        "           <!DOCTYPE html>\n",
        "        <html>\n",
        "        \t<head></head>\n",
        "        \t<body>\n",
        "                <p>{0}</p>\n",
        "        \t</body>\n",
        "        </html>\n",
        "        '''\n",
        "        #<p style=\"color:blue;\">{1}</p>\n",
        "\n",
        "        #gets text from raw text file\n",
        "        text_f = open(self.text_path, 'r')\n",
        "        lines = text_f.read()\n",
        "        text_f.close()\n",
        "\n",
        "        #replaces args + conn w/ html color args + conn\n",
        "        lines = lines.replace('.START', '')\n",
        "        repl_1 = '<font style=\"color:{0};\">{1}</font>'.format(color1, self.Arg1.text)\n",
        "        repl_2 = '<font style=\"color:{0};\">{1}</font>'.format(color2, self.Arg2.text)\n",
        "        repl_con = '<font style=\"color:{0};\">{1}</font>'.format(color_con, self.Relation.connective)\n",
        "        lines = lines.replace(self.Arg1.text, repl_1)\n",
        "        lines = lines.replace(self.Arg2.text, repl_2)\n",
        "        lines = lines.replace(self.Relation.connective, repl_con)\n",
        "\n",
        "        #finds boundaries of text\n",
        "        start = lines.find(repl_1)\n",
        "        end = lines.find(repl_2) + len(repl_2) + len(repl_con)\n",
        "\n",
        "        #check that boundaries are within total text window\n",
        "        if(start-context_len<=0):\n",
        "            start = 0\n",
        "        else:\n",
        "            start = start-context_len\n",
        "        if(end+context_len>=len(lines)):\n",
        "            end = 0\n",
        "        else:\n",
        "            end = end+context_len\n",
        "        context = lines[start:end]\n",
        "\n",
        "        #opens html, writes raw text\n",
        "        html_f = open(output_file, 'w')\n",
        "        html_f.write(self.Relation.type + \": \" + self.Relation.semantic_class)\n",
        "        html_f.write(self.Relation.type_definition)\n",
        "        html_f.write(htmlFile.format(context))\n",
        "        html_f.close()\n",
        "\n",
        "class Arg():\n",
        "    def __init__(self, raw_substring, text_path):\n",
        "        self.text = self.getText(raw_substring, text_path)\n",
        "\n",
        "    #gets the text of the argument. can be in one or multiple chunks.\n",
        "    def getText(self, raw_substring, text_path):\n",
        "        if(raw_substring[-1]==';'):\n",
        "            raw_substring = raw_substring[:-1]\n",
        "        if(';' not in raw_substring):\n",
        "            nums = raw_substring.split(\"..\")\n",
        "            f = open(text_path, 'r')\n",
        "            text = f.read()\n",
        "            f.close()\n",
        "            return text[int(nums[0]):int(nums[1])]\n",
        "        else: #this case is for multi-part args...\n",
        "            pairs = raw_substring.split(\";\")\n",
        "            f = open(text_path, 'r')\n",
        "            text = f.read()\n",
        "            texts = \"\"\n",
        "            for pair in pairs:\n",
        "                nums = pair.split(\"..\")\n",
        "                texts+=text[int(nums[0]):int(nums[1])]+\" \"\n",
        "            return texts\n",
        "\n",
        "class Relation():\n",
        "    def __init__(self, rel_type, connective, semantic_class):\n",
        "        self.type = rel_type\n",
        "        self.types_dict = self.defineTypes()\n",
        "        self.type_definition = self.types_dict[rel_type]\n",
        "        self.semantic_class = semantic_class\n",
        "        self.connective = connective\n",
        "\n",
        "    def defineTypes(self):\n",
        "        defs = '''Explicit - Has an explicit discourse connective. Examples include since, because and therefore.\n",
        "Implicit - Must be inferred, lack the cues of explicit connectives.\n",
        "AltLex - Lack an explicit connective, but contain other phrasal or construction-based evidence for the relation that holds between the arguments. Cases where a discourse relation is inferred between adjacent sentences but where providing an implicit connective leads to redundancy in the expression of the relation.\n",
        "AltLexC - Lack an explicit connective, but contain other phrasal or construction-based evidence for the relation that holds between the arguments. They are a type of AltLex construction, they can be found on their own, separate from other AltLex tokens but have the same fields as AltLex. Examples include so, such and too.\n",
        "Hypophora - Involves a question posed in Arg1 and answer in Arg2. Explicitly marked question-response pairs.\n",
        "EntRel - A relation holds between an entity mentioned in Arg1 and the contents of Arg2.\n",
        "NoRel - Annotated only between adjacent sentences within a paragraph that are not linked to each other by a discourse relation.'''\n",
        "        defs = defs.split('\\n')\n",
        "        dict = {}\n",
        "        for d in defs:\n",
        "            type, definition = d.split(' - ')\n",
        "            dict[type] = definition\n",
        "        return dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HMbhCcNnh7g"
      },
      "source": [
        "<a name='a2'>\n",
        "\n",
        "### Examining the Discourse Unit and Surveying Discourse Relations\n",
        "\n",
        "In this section, let's load a few discourse units and do some basic EDA on the PDTB3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4IDbEJ5ngXK"
      },
      "source": [
        "#First, we need to load the PDTB into Colab from Drive\n",
        "!cp ./drive/MyDrive/Colab/pdtbMerge-v9-3.zip .\n",
        "!unzip  pdtbMerge-v9-3.zip\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo3gteL7n9qw"
      },
      "source": [
        "#Instantiate the DiscourseLoader object\n",
        "loader = DiscourseLoader('pdtbMerge-v9-3/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMrPf5RmpB9g"
      },
      "source": [
        "#Let's make a list of five discourse units\n",
        "discourse_units = []\n",
        "for i in range(5):\n",
        "  discourse_units.append(DiscourseUnit(loader.raw_relations[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyR69TXHpaVO",
        "outputId": "51ba1595-0153-40d0-8e03-f76f1dcaaf2c"
      },
      "source": [
        "#Some basic details about this discourse unit\n",
        "print(\"Type:\", discourse_units[0].Relation.type)\n",
        "print(\"Type Definition:\", discourse_units[0].Relation.type_definition)\n",
        "print(\"Argument #1:\", discourse_units[0].Arg1.text)\n",
        "print(\"Argument #2:\", discourse_units[0].Arg2.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: Explicit\n",
            "Type Definition: Has an explicit discourse connective. Examples include since, because and therefore.\n",
            "Argument #1: however, why limit the practice to the poor, maligned analysts whose ability to see into the future is fragile at best\n",
            "Argument #2: the firms are serious\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es_KvtQ8pfut"
      },
      "source": [
        "#We also included a basic visualization method\n",
        "discourse_units[0].highlightDiscourse(discourse_units[0].text_path, 'discourse_visualization.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkBk5x61qh0X"
      },
      "source": [
        "#This code loads all of the PDTB instances as DiscourseUnits\n",
        "units = []\n",
        "for i in range(len(loader.raw_relations)):\n",
        "  print(i)\n",
        "  try:\n",
        "    units.append(DiscourseUnit(loader.raw_relations[i]))\n",
        "  except:\n",
        "    print(\"Colab Error\")\n",
        "units[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7vFA1hLsCUI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "6aef4557-e79d-4b1a-84c4-4ca7665ffcad"
      },
      "source": [
        "#Look at all those relations! Now let's make a Pandas dataframe and analyze these relations.\n",
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "df['relation'] = [d.Relation.type for d in units]\n",
        "df['semantic_class'] = [d.Relation.semantic_class for d in units]\n",
        "df['connective'] = [d.Relation.connective for d in units]\n",
        "df['arg1'] = [d.Arg1.text for d in units]\n",
        "df['arg2'] = [d.Arg2.text for d in units]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>relation</th>\n",
              "      <th>semantic_class</th>\n",
              "      <th>connective</th>\n",
              "      <th>arg1</th>\n",
              "      <th>arg2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explicit</td>\n",
              "      <td>Contingency.Condition.Arg2-as-cond</td>\n",
              "      <td>if</td>\n",
              "      <td>however, why limit the practice to the poor, m...</td>\n",
              "      <td>the firms are serious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Explicit</td>\n",
              "      <td>Comparison.Concession.Arg2-as-denier</td>\n",
              "      <td>however</td>\n",
              "      <td>I'm delighted that Wall Street is finally tuni...</td>\n",
              "      <td>why limit the practice to the poor, maligned a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Implicit</td>\n",
              "      <td>Expansion.Substitution.Arg2-as-subst</td>\n",
              "      <td>instead</td>\n",
              "      <td>If the firms are serious, however, why limit t...</td>\n",
              "      <td>Why not extend the same harsh standards to the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Explicit</td>\n",
              "      <td>Expansion.Manner.Arg2-as-manner</td>\n",
              "      <td>and</td>\n",
              "      <td>extend the same harsh standards to the sales f...</td>\n",
              "      <td>pay brokers a base salary with annual bonus ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Explicit</td>\n",
              "      <td>Expansion.Conjunction</td>\n",
              "      <td>with</td>\n",
              "      <td>and pay brokers a base salary</td>\n",
              "      <td>annual bonus based on how much money they made...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53286</th>\n",
              "      <td>Explicit</td>\n",
              "      <td>Contingency.Cause.Reason</td>\n",
              "      <td>because</td>\n",
              "      <td>The company has expressed a preference for GM ...</td>\n",
              "      <td>GM has promised it would keep Jaguar independent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53287</th>\n",
              "      <td>Explicit</td>\n",
              "      <td>Temporal.Asynchronous.Precedence</td>\n",
              "      <td>then</td>\n",
              "      <td>when it abandoned a four-year effort to market...</td>\n",
              "      <td>last Friday, Ford's talks about a possible all...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53288</th>\n",
              "      <td>Implicit</td>\n",
              "      <td>Contingency.Cause.Reason</td>\n",
              "      <td>since</td>\n",
              "      <td>GM's interest in Jaguar reflects a desire to h...</td>\n",
              "      <td>Its Opel line has a solid image and a recent s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53289</th>\n",
              "      <td>Explicit</td>\n",
              "      <td>Comparison.Contrast</td>\n",
              "      <td>but</td>\n",
              "      <td>Its Opel line has a solid image and a recent s...</td>\n",
              "      <td>it lacks Jaguar's cachet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53290</th>\n",
              "      <td>Explicit</td>\n",
              "      <td>Expansion.Conjunction</td>\n",
              "      <td>also</td>\n",
              "      <td>GM's interest in Jaguar reflects a desire to h...</td>\n",
              "      <td>GM officials see a lot of potential in marryin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53291 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       relation  ...                                               arg2\n",
              "0      Explicit  ...                              the firms are serious\n",
              "1      Explicit  ...  why limit the practice to the poor, maligned a...\n",
              "2      Implicit  ...  Why not extend the same harsh standards to the...\n",
              "3      Explicit  ...  pay brokers a base salary with annual bonus ba...\n",
              "4      Explicit  ...  annual bonus based on how much money they made...\n",
              "...         ...  ...                                                ...\n",
              "53286  Explicit  ...   GM has promised it would keep Jaguar independent\n",
              "53287  Explicit  ...  last Friday, Ford's talks about a possible all...\n",
              "53288  Implicit  ...  Its Opel line has a solid image and a recent s...\n",
              "53289  Explicit  ...                           it lacks Jaguar's cachet\n",
              "53290  Explicit  ...  GM officials see a lot of potential in marryin...\n",
              "\n",
              "[53291 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "DscXzqCry4Zr",
        "outputId": "895e3bc4-0edf-47ea-ba85-ac5ac7cbcc34"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(df['relation'])\n",
        "plt.title(\"Distribution of Relations By Type\")\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo364NHr0pt8",
        "outputId": "c0dfb6f0-7162-4ac6-8e80-df4669633331"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "df['arg1_count'] = df.arg1.apply(lambda x: len(nltk.word_tokenize(x)))\n",
        "df['arg2_count'] = df.arg2.apply(lambda x: len(nltk.word_tokenize(x)))\n",
        "arg1_count = df['arg1_count']\n",
        "arg2_count = df['arg2_count']\n",
        "df['arg_counts'] = arg1_count + arg2_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci4xk4eZ3-CI",
        "outputId": "b31e0e12-ec47-4630-f6de-1d227a22a9e4"
      },
      "source": [
        "print(\"Average argument length (in words) for explicit relations: \", df[(df['relation']=='Explicit')]['arg_counts'].mean())\n",
        "print(\"Average argument length (in words) for implicit relations: \", df[(df['relation']=='Implicit')]['arg_counts'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average argument length (in words) for explicit relations:  26.49396190397145\n",
            "Average argument length (in words) for implicit relations:  33.02370609981516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EHr_H6B029n",
        "outputId": "d8524125-f039-4e9d-d86a-5fc15aeb6a2f"
      },
      "source": [
        "connectives = df['connective'].value_counts(sort=True, normalize=True)\n",
        "connectives = connectives[:10]\n",
        "connectives"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "and             0.154641\n",
              "                0.141731\n",
              "but             0.083935\n",
              "because         0.055563\n",
              "also            0.040889\n",
              "specifically    0.029517\n",
              "while           0.028241\n",
              "in order        0.024732\n",
              "so              0.024319\n",
              "then            0.023625\n",
              "Name: connective, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0fUezFL0lFh"
      },
      "source": [
        "Looks like most relations are either implicit or explicit. Of those relations, we can tell that implicit relations have arguments that are in total 6-7 words longer on average. Additionally, we see that 'and' and no connective make up almost 30% of relations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4oWgPQ85OXV",
        "outputId": "9872857a-3cb2-4307-882f-583419263d9a"
      },
      "source": [
        "print(len(set(df['semantic_class'])))\n",
        "print(df['semantic_class'].value_counts(sort=True, normalize=True))\n",
        "print(df['semantic_class'].value_counts(sort=True, normalize=True)[-20:].sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n",
            "Expansion.Conjunction                                       0.248072\n",
            "                                                            0.111201\n",
            "Comparison.Concession.Arg2-as-denier                        0.102456\n",
            "Contingency.Cause.Reason                                    0.086638\n",
            "Contingency.Cause.Result                                    0.075172\n",
            "Expansion.Level-of-detail.Arg2-as-detail                    0.060385\n",
            "Temporal.Synchronous                                        0.046837\n",
            "Temporal.Asynchronous.Precedence                            0.039838\n",
            "Comparison.Contrast                                         0.037417\n",
            "Expansion.Instantiation.Arg2-as-instance                    0.034490\n",
            "Contingency.Condition.Arg2-as-cond                          0.030699\n",
            "Contingency.Purpose.Arg2-as-goal                            0.030136\n",
            "Temporal.Asynchronous.Succession                            0.025483\n",
            "Comparison.Concession.Arg1-as-denier                        0.014881\n",
            "Expansion.Substitution.Arg2-as-subst                        0.009364\n",
            "Expansion.Manner.Arg2-as-manner                             0.008125\n",
            "Expansion.Equivalence                                       0.006943\n",
            "Expansion.Disjunction                                       0.006211\n",
            "Expansion.Level-of-detail.Arg1-as-detail                    0.005629\n",
            "Comparison.Similarity                                       0.003678\n",
            "Contingency.Cause+Belief.Reason+Belief                      0.003115\n",
            "Contingency.Purpose.Arg1-as-goal                            0.002252\n",
            "Contingency.Negative-condition.Arg2-as-negCond              0.002064\n",
            "Expansion.Substitution.Arg1-as-subst                        0.002027\n",
            "Expansion.Manner.Arg1-as-manner                             0.001389\n",
            "Contingency.Condition+SpeechAct                             0.001370\n",
            "Contingency.Cause+Belief.Result+Belief                      0.001351\n",
            "Contingency.Condition.Arg1-as-cond                          0.000563\n",
            "Comparison.Concession+SpeechAct.Arg2-as-denier+SpeechAct    0.000507\n",
            "Expansion.Exception.Arg2-as-excpt                           0.000488\n",
            "Expansion.Exception.Arg1-as-excpt                           0.000338\n",
            "Contingency.Negative-condition.Arg1-as-negCond              0.000300\n",
            "Contingency.Cause+SpeechAct.Reason+SpeechAct                0.000244\n",
            "Contingency.Cause+SpeechAct.Result+SpeechAct                0.000188\n",
            "Expansion.Instantiation.Arg1-as-instance                    0.000075\n",
            "Contingency.Negative-cause.NegResult                        0.000075\n",
            "Name: semantic_class, dtype: float64\n",
            "0.038805802105421186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKSPeW3u5gKe"
      },
      "source": [
        "Finally, we turn to the semantic classes. This is the label that we will be predicting with our implicit sense classifier, so it is good to know the distribution of the label type in our dataset. What we find is that this category is highly imbalanced in its classes, with the most occuring class being more than double the size of the second most occuring class, and three times the size of the third most occurring class. We also find that our of 36 categories, the 20 least occuring classes make up less than 4% of all discourse units. **This is a very skewed category**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e4NTVmj7SYs"
      },
      "source": [
        "<a name='b'></a>\n",
        "\n",
        "## Bonus: Visualizing Discourse Model Predictions\n",
        "\n",
        "In this section, we'll move on from simply exploring discourse data and attempt to model it!\n",
        "\n",
        "<a name='b1'></a>\n",
        "\n",
        "### Running a Discourse Model\n",
        "\n",
        "The discourse model we'll be running is Chen, Chu, and Gimpel's DiscoEval implicit sense classifier (which you can find here: https://github.com/ZeweiChu/DiscoEval). Basically, this model takes two arguments are input, and attempts to predicted the semantic discourse class. In this section, we're going to run this model on the default PDTB2 dataset.\n",
        "\n",
        "*Note on Execution*: Because we'd like to run this model with GPU's, this notebook is being run on Google Colab. Since we're running a fairly complex codebase on Colab, I'll zip the files and upload them into this runtime. This method has its drawbacks, in that you may not be able to see every change I make to the model, but we'll deal with that by flashing important code bits and describing important changes in the next section when we run the model on PDTB3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHD4KhIz7R4a"
      },
      "source": [
        "#First, we need to load the DiscoEval model into Colab from Drive\n",
        "!cp ./drive/MyDrive/Colab/DiscoEval-master.zip .\n",
        "!unzip  DiscoEval-master.zip\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PrN_h-EOYcm"
      },
      "source": [
        "!cp ./drive/MyDrive/Colab/SentEval-master.zip .\n",
        "!unzip  SentEval-master.zip\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQQcR3m-AE87"
      },
      "source": [
        "#Install dependencies\n",
        "!pip install transformers tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsYTeVi8_J9V",
        "outputId": "9136ddec-9094-4855-9dbd-a3a236073320"
      },
      "source": [
        "#This command will run the model on PDTB2\n",
        "#Note: you need to enable GPU for this\n",
        "#print(\"config\")\n",
        "#!cd DiscoEval-master/train/ && python config.py --train_path DiscoEval-master/train/ --test_path DiscoEval-master/discoeval/#gonna need flags here\n",
        "#print(\"run\")\n",
        "#!cd DiscoEval-master/train/ && python run.py\n",
        "print(\"shell\")\n",
        "!cd DiscoEval-master/examples/ && sh run_bert.sh 4 avg base"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shell\n",
            "6a86286559a6\n",
            "task: 4\n",
            "layer: avg\n",
            "model type: base\n",
            "Traceback (most recent call last):\n",
            "  File \"bert.py\", line 24, in <module>\n",
            "    import discoeval \n",
            "ModuleNotFoundError: No module named 'discoeval'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}